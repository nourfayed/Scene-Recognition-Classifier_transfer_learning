{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nourfayed/inception_transfer_learning/blob/master/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfc9OohMm4aa",
        "colab_type": "code",
        "outputId": "c8ee3ab2-6d98-46f1-96a1-753fd067e5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8zL91ZynLeD",
        "colab_type": "code",
        "outputId": "4fdd849b-935c-40b2-b6b2-14b922cee2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd gdrive/My Drive/Neural Networks/Files\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Neural Networks/Files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2z7Mf9lnPOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4RrvxjmnVoJ",
        "colab_type": "code",
        "outputId": "81a181ee-01bc-4295-ea8c-0aefe679e8cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_Train=[]\n",
        "Y_TrainLabels=[]\n",
        "Testing_images = []\n",
        "\n",
        "Y_TrainLabels =np.load('labels.npy',allow_pickle=True)\n",
        "X_Train = np.load('train.npy',allow_pickle=True)\n",
        "Testing_images = np.load('TestingImages.npy',allow_pickle=True)\n",
        "\n",
        "print(X_Train.shape)\n",
        "print(\"khalas\")\n",
        "\n",
        "#print(Y_TrainLabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5827, 299, 299, 3)\n",
            "khalas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWf1cI5JnY8c",
        "colab_type": "code",
        "outputId": "4ebd661d-fce3-4a32-8d71-8b0850bb87e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import inception_resnet_v2 as incep_v2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.patches as mpatches\n",
        "from random import shuffle\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "Features_vector = []\n",
        "n_rows = 299\n",
        "n_cols = 299\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def define_model(model, is_training):\n",
        "    model.Image = tf.placeholder(tf.float32, shape=[None, n_rows, n_cols, 3])\n",
        "    with incep_v2.slim.arg_scope(incep_v2.inception_resnet_v2_arg_scope()):\n",
        "        model.logits, model.end_points = incep_v2.inception_resnet_v2(model.Image, is_training=False)\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "class Model_Class:\n",
        "    def __init__(self, is_training):\n",
        "        define_model(self, is_training=is_training)\n",
        "\n",
        "\n",
        "print(\"2\")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "with tf.device('/gpu:0'):\n",
        "    model = Model_Class(False)\n",
        "\n",
        "print(\"done\")\n",
        "\n",
        "model.saver = tf.train.Saver()\n",
        "model.saver.restore(sess,\"\\inception_resnet_v2_2016_08_30.ckpt\")\n",
        "predictions_model = model.end_points[\"PreLogitsFlatten\"]\n",
        "\n",
        "print(\"4\")\n",
        "\n",
        "Labels=[]\n",
        "for i in range (len(X_Train)):\n",
        "    img=X_Train[i]\n",
        "    label=Y_TrainLabels[i]\n",
        "    tmp = sess.run(predictions_model, feed_dict={model.Image: [img]})\n",
        "    Features_vector.append(tmp)\n",
        "    Labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "print(\"5\")\n",
        "\n",
        "\n",
        "Testing_features=[]\n",
        "for i in range (len(Testing_images)):\n",
        "  img=Testing_images[i]\n",
        "  tmp = sess.run(predictions_model, feed_dict={model.Image: [img]})\n",
        "  Testing_features.append(tmp)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(np.shape(Features_vector))\n",
        "print(np.shape(Testing_features))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "done\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from \\inception_resnet_v2_2016_08_30.ckpt\n",
            "4\n",
            "5\n",
            "(5827, 1, 1536)\n",
            "(771, 1, 1536)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Hxe5OJC_Wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Features_vector = np.array(Features_vector)\n",
        "Features_vector = Features_vector.reshape((5827,1536))\n",
        "Testing_features=np.array(Testing_features)\n",
        "Testing_features=Testing_features.reshape((771,1536))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mve6z73vEcoJ",
        "colab_type": "code",
        "outputId": "b284b2e9-8129-4d52-8b8a-a2e4496e2585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import numpy as np\n",
        "\n",
        "#x, y, z = np.shape(Features_vector)\n",
        "#Features_vector = np.reshape(Features_vector, (x, y * z))\n",
        "#x,feature_length = np.shape(Features_vector)\n",
        "\n",
        "input_layer = input_data(shape=[None ,1536], name='input')\n",
        "#conv1 = conv_2d(input_layer, 32, 5, activation='relu')\n",
        "#pool1 = max_pool_2d(conv1, 5)\n",
        "fully_layer = fully_connected(input_layer, 10, activation='relu')\n",
        "#fully_layer = dropout(fully_layer, 0.5)\n",
        "\n",
        "#fully_layer2 = fully_connected(fully_layer, 512, activation='relu')\n",
        "#fully_layer2 = dropout(fully_layer2, 0.6)\n",
        "print(\"1\")\n",
        "cnn_layers = fully_connected(fully_layer, 10, activation='softmax')\n",
        "regression = regression(cnn_layers, optimizer='sgd', learning_rate=0.001, loss='categorical_crossentropy',\n",
        "                        name='targets')\n",
        "cnn_model = tflearn.DNN(regression, tensorboard_dir='log', tensorboard_verbose=0)\n",
        "print(\"2\")\n",
        " \n",
        "  \n",
        "\n",
        "cnn_model.fit({'input': Features_vector}, {'targets': Labels}, n_epoch=50,\n",
        "          validation_set=0.1,batch_size=8,  shuffle=True,    \n",
        "          show_metric=True, run_id='inception+cnn13')\n",
        "print(\"khalas l fit\")\n",
        "cnn_model.save('the_cnn_model15.tfl')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 32799  | total loss: \u001b[1m\u001b[32m2.23261\u001b[0m\u001b[0m | time: 34.125s\n",
            "| SGD | epoch: 050 | loss: 2.23261 - acc: 0.1465 -- iter: 5240/5244\n",
            "Training Step: 32800  | total loss: \u001b[1m\u001b[32m2.22282\u001b[0m\u001b[0m | time: 35.192s\n",
            "| SGD | epoch: 050 | loss: 2.22282 - acc: 0.1443 | val_loss: 2.21723 - val_acc: 0.1252 -- iter: 5244/5244\n",
            "--\n",
            "khalas l fit\n",
            "INFO:tensorflow:/content/gdrive/My Drive/Neural Networks/Files/the_cnn_model15.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8sfIFDuTftY",
        "colab_type": "code",
        "outputId": "a6aef604-3609-451d-806c-87c8c3b1d280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Neural Networks/Files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jI_Bj0NWk14",
        "colab_type": "code",
        "outputId": "7424edbb-5455-4f42-a85d-83aad86dee24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "#cnn_model = tflearn.DNN(regression, tensorboard_dir='log', tensorboard_verbose=0)\n",
        "#cnn_model.load('the_cnn_model13.tfl')\n",
        "predictions=[]\n",
        "\n",
        "#for i in range (len(Testing_features)):\n",
        " \n",
        "prediction = cnn_model.predict(Testing_features)\n",
        "print(np.shape(prediction)) \n",
        "print(prediction)\n",
        "for i in range (len(prediction)):\n",
        "  tmp=-1\n",
        "  mx=0\n",
        "  for j in range (len(prediction[i])):\n",
        "    if(prediction[i][j]>tmp):\n",
        "      tmp=prediction[i][j]\n",
        "      mx=j\n",
        "  predictions.append(mx+1)\n",
        " \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "print(np.shape(predictions))\n",
        "print(predictions)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(771, 10)\n",
            "[[0.11622455 0.19260702 0.07247151 ... 0.01205625 0.03022451 0.03143079]\n",
            " [0.00683985 0.00700419 0.00882042 ... 0.07697919 0.27826744 0.06826711]\n",
            " [0.04224209 0.10200424 0.05137166 ... 0.08869446 0.04990113 0.16786417]\n",
            " ...\n",
            " [0.01694723 0.04470484 0.2729958  ... 0.02880161 0.16552486 0.08142993]\n",
            " [0.3466117  0.19153307 0.03024846 ... 0.02940763 0.17501181 0.08592521]\n",
            " [0.31138927 0.17548293 0.0065417  ... 0.09205704 0.05036405 0.14861195]]\n",
            "(771,)\n",
            "[7, 4, 4, 10, 4, 2, 8, 4, 10, 7, 5, 1, 4, 3, 8, 3, 3, 6, 7, 8, 7, 3, 5, 7, 2, 4, 2, 3, 1, 1, 7, 6, 9, 7, 10, 2, 1, 10, 2, 9, 7, 1, 7, 6, 8, 10, 7, 2, 1, 3, 5, 9, 7, 3, 7, 1, 2, 7, 10, 6, 10, 1, 1, 10, 1, 8, 8, 3, 8, 9, 10, 3, 10, 1, 3, 3, 2, 3, 4, 3, 2, 8, 7, 4, 3, 8, 7, 3, 10, 8, 1, 4, 8, 2, 2, 7, 10, 7, 1, 5, 8, 10, 6, 7, 10, 1, 3, 1, 3, 1, 4, 7, 5, 2, 2, 7, 4, 1, 6, 5, 3, 7, 8, 1, 7, 7, 8, 5, 1, 9, 5, 2, 1, 8, 2, 1, 7, 2, 1, 7, 7, 8, 7, 1, 1, 3, 8, 1, 2, 1, 7, 3, 1, 9, 8, 3, 7, 4, 4, 2, 2, 5, 7, 7, 7, 5, 1, 2, 2, 10, 10, 8, 7, 8, 4, 10, 10, 7, 1, 4, 1, 2, 3, 4, 1, 1, 2, 1, 10, 7, 10, 10, 2, 2, 7, 4, 1, 9, 7, 1, 3, 3, 4, 1, 1, 1, 4, 7, 7, 5, 4, 7, 10, 3, 1, 3, 3, 1, 5, 1, 3, 5, 1, 2, 4, 7, 7, 10, 2, 8, 9, 4, 1, 2, 2, 9, 3, 6, 7, 4, 9, 10, 10, 2, 4, 8, 2, 7, 10, 3, 2, 6, 3, 2, 2, 7, 3, 4, 3, 2, 7, 1, 3, 7, 10, 5, 2, 1, 6, 4, 8, 7, 6, 1, 6, 6, 7, 2, 2, 2, 1, 2, 1, 3, 1, 2, 3, 2, 9, 1, 7, 4, 8, 8, 6, 3, 7, 2, 8, 10, 5, 10, 8, 5, 1, 5, 3, 7, 2, 1, 1, 1, 8, 3, 10, 6, 2, 5, 3, 8, 7, 10, 7, 10, 7, 1, 2, 2, 7, 1, 1, 10, 8, 2, 2, 10, 7, 9, 7, 1, 10, 5, 7, 10, 10, 2, 10, 7, 3, 1, 9, 1, 4, 1, 8, 3, 4, 10, 7, 4, 9, 5, 1, 9, 6, 3, 4, 4, 5, 8, 4, 7, 8, 3, 7, 5, 7, 10, 9, 6, 2, 7, 2, 5, 7, 8, 8, 8, 8, 7, 3, 8, 7, 2, 7, 3, 2, 7, 3, 9, 1, 3, 4, 5, 4, 10, 7, 3, 8, 2, 1, 8, 1, 2, 8, 5, 8, 8, 3, 7, 9, 6, 4, 8, 4, 9, 3, 9, 1, 6, 7, 3, 2, 10, 1, 7, 5, 4, 1, 1, 2, 3, 7, 7, 4, 7, 2, 3, 5, 10, 9, 7, 9, 5, 7, 1, 10, 3, 6, 2, 10, 2, 10, 4, 1, 3, 3, 1, 4, 6, 5, 4, 3, 3, 10, 3, 8, 1, 4, 8, 5, 2, 5, 10, 8, 7, 8, 7, 9, 9, 3, 2, 7, 3, 2, 2, 3, 7, 1, 7, 9, 1, 1, 1, 7, 3, 5, 1, 3, 10, 9, 7, 2, 4, 3, 7, 2, 8, 3, 1, 9, 7, 1, 5, 8, 1, 1, 3, 1, 9, 2, 1, 4, 2, 4, 1, 5, 7, 1, 9, 5, 2, 2, 1, 2, 7, 4, 3, 8, 3, 9, 2, 2, 4, 5, 5, 1, 1, 6, 3, 1, 3, 2, 3, 2, 3, 8, 10, 2, 1, 4, 7, 6, 2, 1, 3, 8, 1, 10, 2, 2, 2, 3, 2, 6, 10, 1, 3, 5, 8, 2, 7, 10, 7, 9, 5, 10, 10, 10, 3, 1, 1, 1, 2, 8, 1, 10, 1, 2, 5, 4, 2, 7, 5, 2, 10, 4, 3, 9, 4, 1, 2, 7, 10, 10, 9, 1, 3, 7, 8, 5, 8, 9, 2, 1, 1, 1, 7, 4, 7, 7, 3, 7, 4, 5, 7, 3, 1, 10, 1, 9, 2, 1, 7, 8, 8, 3, 1, 10, 7, 1, 2, 5, 2, 8, 1, 1, 4, 6, 1, 5, 10, 8, 10, 3, 1, 8, 1, 2, 10, 4, 7, 3, 8, 5, 7, 4, 5, 10, 7, 7, 3, 3, 5, 9, 4, 1, 7, 1, 7, 8, 8, 2, 3, 1, 10, 1, 8, 10, 7, 9, 2, 9, 8, 2, 1, 10, 9, 1, 1, 4, 10, 2, 10, 8, 10, 1, 6, 1, 1, 3, 3, 4, 7, 7, 3, 1, 10, 1, 10, 8, 3, 1, 10, 10, 4, 7, 2, 3, 3, 5, 2, 7, 7, 2, 7, 4, 8, 1, 2, 5, 2, 8, 2, 5, 4, 2, 10, 3, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVq4klRUUTMV",
        "colab_type": "code",
        "outputId": "fa88df4a-bbb3-422e-83c2-d45fb111e864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import csv\n",
        "\n",
        "path = '/content/gdrive/My Drive/Neural Networks/test/*.jpg'\n",
        "pathes = glob.glob(path)\n",
        "\n",
        "print(len(predictions))\n",
        "print(len(pathes))\n",
        "\n",
        "filename = \"Model15.csv\" \n",
        "with open(filename, 'w') as csvfile: \n",
        "     \n",
        "    csvwriter = csv.writer(csvfile) \n",
        " \n",
        "    for i in range(len(predictions)):\n",
        "       s=pathes[i][46:len(pathes[i])]\n",
        "       tmp=[s,predictions[i]]\n",
        "       csvwriter.writerow(tmp)\n",
        "\n",
        "    csvfile.close()\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "771\n",
            "771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMEUfa_rz4Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "filename = \"testcsv3.csv\"\n",
        "  \n",
        "# writing to csv file \n",
        "with open(filename, 'w') as csvfile: \n",
        "    # creating a csv writer object \n",
        "    csvwriter = csv.writer(csvfile) \n",
        "    tmp=[1,2]\n",
        "    for i in range(20):\n",
        "       csvwriter.writerow(tmp)\n",
        "\n",
        "    csvfile.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}